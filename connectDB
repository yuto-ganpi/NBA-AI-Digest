
from pymongo.mongo_client import MongoClient
from pymongo.server_api import ServerApi
from pprint import pprint
import datetime
import setting
import scrapying
import chatgpt
import postblogger

mongodbatlas_pass = setting.mongodbatlas_pass

uri = f'mongodb+srv://ganpi_atlas:{mongodbatlas_pass}@cluster0.cvknuco.mongodb.net/?retryWrites=true&w=majority'

# Create a new client and connect to the server
client = MongoClient(uri, server_api=ServerApi('1'))

# Send a ping to confirm a successful connection
try:
    client.admin.command('ping')
    print("Pinged your deployment. You successfully connected to MongoDB!")
except Exception as e:
    print(e)
    
db = client['nbaaimedia']
rapidapi = db['rapidapi']

def make_basic_info():
    basic_info = scrapying.rapidapi()

    for data in basic_info:
        rapidapi.insert_one(data)
        
def insert_content():
    # データを取り出してcontentを作成し、contentカラムに追加
    for data in rapidapi.find({"source": "nba"}):
        url = data["url"]
        content = scrapying.make_content(url)
        rapidapi.update_one({"url": url}, {"$set": {"content": content}})
    return

# "source"がnbaでないデータのカラム"content"を削除
# query = {"source": {"$ne": "nba"}}
# update = {"$unset": {"content": 1}}
# rapidapi.update_many(query, update)

client_id = setting.c_id
client_secret = setting.c_sr
counter = 0

for data in rapidapi.find({"source": "nba"}):
    counter += 1
    title_db = data["title"]
    content_db = data["content"]
    url_db = data["url"]
    title_gpt, summary_gpt = chatgpt.make_summary(article_title=title_db, article_body=content_db, article_url=url_db)
    rapidapi.update_one({"_id": data["_id"]}, {"$set": {"title_ja": title_gpt, "summary": summary_gpt}})
    postblogger.post_blogger(client_id=client_id, client_secret=client_secret, title=title_gpt, content=summary_gpt)
    if counter == 10:
        break
    